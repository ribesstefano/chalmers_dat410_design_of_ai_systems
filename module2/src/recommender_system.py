# -*- coding: utf-8 -*-
"""assignment_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wLhtbi13Jvz_KSfHT3BDUDVoJQrGOAhd

# DAT410 - Assignment 2: Recommender Systems

---

Authors: Daniele Murgolo, Stefano Ribes.

| Student | Mail    | Hours spent |
|---      |---      |---          |
| Daniele Murgolo | murgolo@student.chalmers.se | 12 |
| Stefano Ribes | ribes@chalmers.se | 12 |

## Implementation

This section reports and describes how we implemented a simple reccomandation system.
"""

import os
import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_probability as tfp
import keras
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/gdrive', force_remount=True)

drive_mounted = True

"""Read the CSV data via `pandas` and extract the $X$ and $Y$ matrices to `numpy`. Then, randomly initialize the matrix $\Theta$."""

prj_dir = '/gdrive/My Drive/Group_Assignments/DAT410/'

x_data = pd.read_csv(os.path.join(prj_dir, 'movie_genres.csv'), index_col=0)
y_data = pd.read_csv(os.path.join(prj_dir, 'user_reviews.csv'), index_col=0)
# Remove title column (the first one) and get the data into matrices.
x = x_data.iloc[:, 1:].to_numpy(na_value=0) # shape: (movies, genres)
y = y_data.iloc[:, 1:].to_numpy(na_value=0) # shape: (users, movies)
theta = np.random.randn(x.shape[1], y.shape[0]) # shape: (genres, users)
print(f'Initial value is {theta} with MSE: {np.sqrt(np.mean((x @ theta - y.T)**2))}')
# y_data.head()

"""Convert the `numpy` arrays into `tensorflow` variables. After defining the `rmse` loss function, we can minimize it through the available `tfp.math.minimize` function. In this way, we obtain a trained matrix $\Theta$.

To minimize the RMSE between $X \cdot \Theta$ and $Y$, we decided to exploit the Adam optimizer with learning rate set at 0.1 (we experimented with stochastic gradient descent also, but Adam gave us slightly better results in fewer steps).
"""

x_var = tf.Variable(x, trainable=False, dtype=tf.float64)
y_var = tf.Variable(y, trainable=False, dtype=tf.float64)
theta_var = tf.Variable(theta, trainable=True, dtype=tf.float64)
# `rmse` is the RMSE function to minimize.
rmse = lambda: tf.math.sqrt(tf.math.reduce_mean((x_var @ theta_var - tf.transpose(y_var))**2))
losses = tfp.math.minimize(rmse,
                           num_steps=200,
                           trainable_variables=[theta_var],
                           optimizer=tf.optimizers.Adam(learning_rate=0.1)
                           # optimizer=tf.optimizers.SGD(learning_rate=0.1, momentum=0.9, clipnorm=1.0, clipvalue=0.1)
                        )
print(f'Optimized value is {theta_var} with MSE: {losses[-1]}')

"""If we plot the MSE over time, we can clearly see how the optimizer updates $\Theta$ in order to minimize the MSE."""

plt.plot(losses)
plt.xlabel('Steps')
plt.ylabel('RMSE')
plt.grid()
plt.title('RMSE minimization')
plt.show()

"""Finally, make the predictions by multipling $X$ and $\Theta$ and taking the indexes of the maximum values. The indexes are then utilized to extract the movie titles from the original dataframes."""

y_pred = (x_var @ theta_var)[:, :5]
movies = list(y_data.iloc[:5, tf.math.argmax(y_pred)])
users = list(y_data['User'][:5])
for m, u in zip(movies, users):
    print(f'The system suggests to the user {u}, the movie: "{m}"')

"""### Strengths and Weaknesses

Our system shows the following strong features:

* It's simple: the implementation is straightforward and doesn't require expensive resources, in terms of time, to train and utilize;
* Easy to update: in case $Y$ is updated with new ratings, the system can be quickly updated to its simplicity.

We believe that our system exhibits the following weaknesses instead:

* There might be hidden 'sociatal' biases towards some users, which are not taking care of by our system;
* The loss function takes into account the whole $Y$ matrix, even though some of the ratings might be missing and therefore lead to overfitting;
* The loss function doesn't account for latent information. One example being *which* movies users have rated, on top of *how* they rated them.

## Discussion

Assessing the recommendation system is a challenging task. We can extrapolate these challenges from the papers provided in the module.

The first problem is the sparsity of the features. If we take as an example the Netflix Prize Award, we can see that not every user leaves a rating to the movie. It reduces the possibility of finding a set of similar users. Furthermore, we also have a problem with synonymy. The system will consider items formed by multiple listings, for example, movie trilogies, as different items. The same element will be counted multiple times.

Another problem that may arise is the lack of data on a user when this is first introduced to the system. The model is going to struggle to suggest an item immediately. In addition, when a new item is introduced into the dataset, the lack of feedback from users can create a latency.Moreover, if the system provides recommendations too personalized to the users, they may think that their privacy is being lost. It may cause resentment and disbelief in the system.

Finally, we have identified a scalability problem. With an extensive amount of data created by user-item interactions, it is easy to see how the size of these datasets can increase exponentially.
"""